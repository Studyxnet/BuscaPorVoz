{"Name":"API.AI SDK","Id":1838,"Alias":"ApiAiSDK","Description":"# API.AI Xamarin SDK\n\nXamarin SDK for [Api.ai](http://api.ai) natural language processing service makes it easy to integrate speech interfaces into your Xamarin apps.\n\nPlease refer to the detailed docs at [api.ai](http://api.ai/docs/).\n\n## \u003ca name=\"pre-conditions\"/\u003e Before you start coding:\n* To use the SDK, you\u0027d need to [create an Api.ai account](https://console.api.ai/api-client/#/signup).\n* [Create an agent](https://console.api.ai/api-client/#/newAgent) to get two API keys: subscription key and client access token.\n\n## \u003ca name=\"integration\"/\u003e Integration\n* [Initialize the SDK](#initialize-sdk)\n* [Process results](#process-results)\n* [Start voice input](#start-voice-input)\n* [Sample app](#sample-app)\n\n### \u003ca name=\"initialize-sdk\"\u003eInitialize the SDK\n\n```csharp\nvar config = new AIConfiguration(\"subscriptionKey\", \"accessToken\", \n                                                SupportedLanguage.English);\naiService = AIService.CreateService(config);\n\naiService.OnResult += AiService_OnResult;\naiService.OnError += AiService_OnError;\n```\n\n_(Note: In Android you also should pass context to the `CreateService` method)_\n\n### \u003ca name=\"process-results\" /\u003eProcess results\nAnd this code snippet for processing results\n\n```csharp\nvoid AiService_OnResult(AIResponse response)\n{\n    //TODO: Implement DoInUiThread function according to your platform\n    DoInUiThread(() =\u003e\n        {\n            if (!response.IsError)\n            {\n                // TODO: Do some response processing\n            }\n            else\n            {\n                // TODO: Do some server error processing\n            }\n        }\n    );\n}\n\nvoid AiService_OnError(AIServiceException exception)\n{\n    Log.Debug(TAG, \"AIService Error: \", exception.ToString());\n    // TODO: Do some error processing\n}\n```\n\n### \u003ca name=\"start-voice-input\" /\u003eStart voice input\nStart listening with `aiService.StartListening();` method.\n\n### \u003ca name=\"sample-app\" /\u003eSample app\nFor more details see GettingStarted section in Xamarin Components Store and the [example app](https://github.com/api-ai/api-ai-xamarin-sample).\n","Version":"1.2.0","Summary":"API.AI SDK makes it easy to integrate speech recognition and natural language processing service into your application.","QuickStart":"# Getting Started with Api.ai Xamarin SDK\n\n* [Before you start coding](#pre-conditions)\n* [Modify app permissions](#modify-app-permissions)\n* [Initialize the SDK](#initialize-sdk)\n* [Define event handlers](#define-event-handlers)\n* [Start voice input](#start-voice-input)\n* [Define voice input listeners (optional)](#define-voice-input-listeners)\n\n## \u003ca name=\"pre-conditions\" /\u003e Before you start coding\n* To use the SDK, you\u0027ll need to [create an Api.ai account](https://console.api.ai/api-client/#/signup)\n* [Create an agent](https://console.api.ai/api-client/#/newAgent) to get two API keys: subscription key and client access token.\n\n## \u003ca name=\"modify-app-permissions\" /\u003e Modify app permissions\n* On Android:\nModify ```AndroidManifest.xml``` and add **Internet** and **Audio recording** permissions:\n\n    ```xml\n    \u003cuses-permission android:name=\"android.permission.INTERNET\" /\u003e\n    \u003cuses-permission android:name=\"android.permission.RECORD_AUDIO\" /\u003e\n    ```\n    \n* On iOS - no extra actions are required.\n\n## \u003ca name=\"initialize-sdk\" /\u003e Initialize the SDK\n1. Connect API.AI SDK Component to your app.\n2. Get subscriptionKey and client access token keys from Api.ai developer console =\u003e agent\u0027s settings.\n3. In your app code create instance of the `AIConfiguration` class. You must specify **subscription key**, **client access token** and a language for the agent(see `SupportedLanguage` enumeration and [supported languages](http://api.ai/docs/reference/#languages)).\n    \n    ```csharp\n    var config = new AIConfiguration(\"subscriptionKey\", \"accessToken\", \n                                                SupportedLanguage.English);\n    ```\n\n4.  Then create AIService instance using `AIService.CreateService` method.\n    * On iOS platform you need only AIConfiguration instance\n        \n        ```csharp\n        aiService = AIService.CreateService(config);\n        ```\n\n    * On Android platform you need also context and optionally can specify recognition engine option\n\n        ```csharp\n        aiService = AIService.CreateService(context, config);\n        ```\n\n## \u003ca name=\"define-event-handlers\" /\u003e Define event handlers\nNow you need to specify event handlers for Api.ai results processing:\n\n```csharp\naiService.OnResult += AiService_OnResult;\naiService.OnError += AiService_OnError;\n```\n\nSample `OnResult` handler. Make sure you interact with the UI in the UI thread:\n\n```csharp\nvoid AiService_OnResult(AIResponse response)\n{\n    RunOnUiThread(() =\u003e\n        {\n            if (!response.IsError)\n            {\n                if (response.Result != null)\n                {\n                    resultTextView.Text = response.Result.Action;    \n                }\n            }\n            else\n            {\n                resultTextView.Text = response.Status.ErrorDetails;\n            }\n        }\n    );\n}\n```\n\nSample `OnError` handler:\n\n```csharp\nvoid AiService_OnError(AIServiceException exception)\n{\n    Log.Debug(TAG, \"AIService Error: \", exception.ToString());\n}\n```\n\n## \u003ca name=\"start-voice-input\" /\u003e Start voice input\nNow for start listening call `StartListening` method. E.g. it could be started when the user presses the mic button:\n\n```csharp\naiService.StartListening();\n```\n\n## \u003ca name=\"define-voice-input-listeners\" /\u003e Define additional listeners for voice input\nAlso you can add additional listeners for another recognition events:\n\n```csharp\naiService.ListeningStarted += AiService_ListeningStarted;\naiService.ListeningFinished += AiService_ListeningFinished;\naiService.AudioLevelChanged += AiService_AudioLevelChanged;\n```\n  \n\n\n","Hash":"c058997df79beef0d21fe5f46afee777","TargetPlatforms":["ios","android"],"TrialHash":null}